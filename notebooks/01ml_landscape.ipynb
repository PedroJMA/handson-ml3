{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning by GÃ©ron\n",
    "\n",
    "Part I. The Fundamentals of Machine Learning \n",
    "\n",
    "# 1. The Machine Learning landscape \n",
    "\n",
    "A look at the map and learn about the main regions and the most notable landmarks: \n",
    "- supervised versus unsupervised learning\n",
    "- online versus batch learning, \n",
    "- instance based versus model-based learning\n",
    "\n",
    "Then we will look at the workflow of a typical ML project, discuss the main challenges you may face, and cover how to evaluate and fine-tune a Machine Learning system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning? \n",
    "\n",
    "Machine Learning is the science (and art) of programming computes so they can *learn from data*.\n",
    "\n",
    "## Why Use Machine Learning? \n",
    "\n",
    "Machine Learning can help humans learn. ML algorithms can be inspected to see what they have learned (although for some algorithms this can be tricky). \n",
    "Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called *data mining*. \n",
    "\n",
    "To summarize, Machine Learning is great for: \n",
    "- Problems for which existing solutions require a lot of fine-tuning or long lists of rules: one Machine learning algorithm can often simplify code and perform better than the traditional approach. \n",
    "\n",
    "- Complex problems for which using a traditional approach yields no good solution: the best Machine Learning techniques can perhaps find a solution. \n",
    "\n",
    "- Fluctuating environments: a Machine Learning system can adapt to new data. \n",
    "\n",
    "- Getting insights about complex problems and large amounts of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "\n",
    "\n",
    "### Supervised/Unsupervised Learning \n",
    "\n",
    "Machine Learning systems can be classified according to the amount and type of supervision they get during training. \n",
    "There are four major categories: \n",
    "1. supervised learning,\n",
    "2. unsupervised learning,\n",
    "3. smisupervised learning, \n",
    "4. and Reinforcement learning.\n",
    "\n",
    "#### Supervised Learning\n",
    "\n",
    "In *supervised learning*, the training set you feed to the algorithm includes the desired solutions, called *labels*. \n",
    "\n",
    "A typical supervised learning task is *classification* given a set of data with their *class*. \n",
    "\n",
    "Another typical task is to predict a *target* numeric value given a set of *features* called *predictors*. This sort of task is called *regression*. To train the system, you need to give it many examples of instances including both their predictors and their labels. \n",
    "\n",
    "Some regression algorithms can be used for classification as well, and vice versa. For example, *Logistic Regression* is commonly used for classification, as it can output a value that corresponds to the probability of belonging to a given class. \n",
    "\n",
    "> Note: In machine learning an *attribute* is a data type, while a *feature* has several meanings, depending on the context, but generally means an attribute plus its value. \n",
    "Many people use the words *attribute* and *feature* interchangeably. \n",
    "\n",
    "Some of the most important supervised learning algorithms: \n",
    "- k-nearest neighbors\n",
    "- linear regression\n",
    "- logistic regression \n",
    "- Support Vector Machines (SVMs)\n",
    "- Decision Trees and Random Forests \n",
    "- Neural Networks \n",
    "\n",
    "some neural network architectures can be unsupervised. They can also be semisupervised and unsupervised pretraining. \n",
    "\n",
    "\n",
    "#### Unsupervised learning \n",
    "\n",
    "In *unsupervised learning* the training data is unlabeled. The system tries to learn without a teacher. \n",
    "\n",
    "Some of themost important unsupervised learning algorithms (ch8-ch9): \n",
    "* Clustering \n",
    "    - K-Means\n",
    "    - DBSCAN\n",
    "    - Hierarchical Cluster Analysis (HCA)\n",
    "* Anomaly detection and novelty detection\n",
    "    - One-class SVM\n",
    "    - Isolation Forest\n",
    "* Visualization and dimensionality reduction \n",
    "    - Principal Component Analysis (PCA) \n",
    "    - Kernel PCA\n",
    "    - Locally Linear Embedding (LLE)\n",
    "    - t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "* Association rule learning \n",
    "    - Apriori\n",
    "    - Eclat\n",
    "\n",
    "*Visualization* algorithms are also good examples of unsupervised learning algorithms: you feed them a lot of complex and unlabeled data, and they output a 2D and 3D representation of our data that can easily be plotted. \n",
    "These algorithms try to preserve as much structure as they can so that you can understand how the data is organized and perhaps identify unsuspected patterns. \n",
    "\n",
    "A realted task is *dimensinality reduction*, in which the goal is to simplify the data without losing too much information. \n",
    "One way to do this is to merge several correlated features into one. \n",
    "This is called *feature extraction*. \n",
    "\n",
    "> Note: It is often a good idea to try to reduce the dimension of your training data using a dimensionality reduction algorithm before you feed it to another Machine Learning algorithm (such as a supervised learning algorithm). It will run much faster, the data will take up less disk and memory space, and in some cases it may also perform better. \n",
    "\n",
    "Yet another important unsupervised task is *anomaly detection*. The system is shown mostly normal instances during training, so it learns to recognize them; then, when it sees a new instance, it can tell whether it looks like a normal one or whether it is likely an anomaly. \n",
    "A very similar task is *novelty detection*: it aims to detect new instances that look different from all instances in the training set. \n",
    "\n",
    "Finally, another common unsupervised task is *association rule learning*, in which the goal is to dig into large amounts of data and discover interesting relations between attributes. \n",
    "\n",
    "\n",
    "#### Semisupervised Learning \n",
    "Since labeling data is usually time-consuming and costly, you will often have plenty of unlabeled instances, and few labeled instances. \n",
    "Some algorithms can deal with data that's partialy labeled. \n",
    "This is called *semisupervised learning*. \n",
    "\n",
    "Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms. \n",
    "For example, *deep belief networks* (DBNs) are based on unsupervised components called *restricted Boltzmann machines* (RBMs) stacked on top of one another. \n",
    "RBMs are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques. \n",
    "\n",
    "#### Reinforcement Learning \n",
    "\n",
    "*Reinforcement Leanring* is a very different beast. \n",
    "The learning system, called an *agent* in this context, can observe the environment, select and perform actions, and get *rewards* in return (or *penalties* in the form of negative rewards). \n",
    "It must then learn by itself what is the best strategy, called a *policy*, to get the most reward over time. \n",
    "A policy defines what action the agent should choose when it in a given situation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Online Learning \n",
    "\n",
    "Another criterion used to classify Machine Learning systems is whether or not the system can learn incrementally from a stream of incoming data. \n",
    "\n",
    "#### Batch Learning \n",
    "In *batch learning*, the system is **incapable of learning incrementally**: it must be trained using all the available data. \n",
    "This will generally take a lot of time and computing resources, so it is typically done offline. \n",
    "First the system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned. This is called *offline learning*. \n",
    "\n",
    "If you want a batch learning system to know about new data, you need to train a new version of the system from scratch on the full dataset (not just the new data, but also the old data), then stop the old system and replace it with the new one. \n",
    "\n",
    "Fortunately, the whole process of training, evaluating, and launching a Machine Learning system can be automated fairly easily, so even a batch learning system can adapt to change. \n",
    "Simply update the data and train a new version of the system from scratch as often as needed. \n",
    "\n",
    "This solution is simple and often works finr, but training using the full set of data can take many hours. If your system needs to adapt to rapidly chaning data, then you need a more reactive solution. \n",
    "\n",
    "#### Online Learning\n",
    "In *online learning*, you train the system incrementally by feeding it data instances sequentially, either individually or in small groups called *mini-batches*. \n",
    "Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives. \n",
    "\n",
    "Online learning is great for systems that receive data as a continuous flow and need to adapt to change rapidly or autonomously. \n",
    "It is also a good option if you have limited computing resources: once an online leanring system has learned about new data instances, it does not need them anymore, so you can discard them (unless you want to be able to roll back to a previous state and \"repay\" the data). \n",
    "This can save a huge amount of space. \n",
    "\n",
    "Online learning algorithms can also be used to train systems on huge datasets that cannot fit in one machine's main memory (this is called **out-of-core learning**). \n",
    "The algorithm loads part of the data, runs a training step on the data, and repeats the process until it has run on all of the data. \n",
    "\n",
    "> Note: Out-of-core learning is usually done offline (i.e., not on the live system), so *online learning* can be a confusing name. Think of it as **incremental learning**. \n",
    "\n",
    "One important parameter of online learning systems is how fast they should adapt to changing data: this is called the **learning rate**. \n",
    "If you set a high learning rate, then you system will rapidly adapt to new data, but it will also tend to quickly forget the old data. \n",
    "Conversely, if you set a low learning rate, the system will have more inertia; that is, it will learn more slowly, but it will also be less sensitive to noise in the new data or to sequences of nonrepresentative data points (outliers). \n",
    "\n",
    "A bit challenge with online learning is that if bad data is fed to the system, the system's performance will gradually decline. \n",
    "If it's a live system, your clients will notice. \n",
    "To reduce this risk, you need to monitor your system closely and promptly switch learning off (and possibly revert to a previously working state) if you detect a drop in performance. \n",
    "You may also want to monitor the input data and react to abnormal data (e.g., using an anomaly detection algorithm). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance-Based versus Model-Based Learning \n",
    "One more way to categorize Machine Learning systems is by how they *generalize*. \n",
    "Most Machine Learning tasks are about making predictions. \n",
    "This means that given a number of trainign examples, the system need to be able to make good prediction for (generalize to) examples it has never seen before. \n",
    "Having a good performance measure on the training data is good, but insufficient; the true goal is to perform well on new instantces. \n",
    "\n",
    "There are two main approaches to generalization: instance-based learning and model-based learning. \n",
    "\n",
    "#### Instance-based Learning \n",
    "Possibly the most trivial form of learning is simply to learn by heart. \n",
    "This requires a *measure of similarity* between two email. A (very basic) similarity measure between two email could be to count the number of words they have in common. \n",
    "\n",
    "This is called *instance-based learning*: the system learns the examples by heart, then generalizes to new cases by using a similarity measure to compare them to the learned examples (or a subset of them). \n",
    "\n",
    "#### Model-based Learning \n",
    "Another way to generalize from a set of examples is to build a model of these examples and then use that model to make *predictions*. This is called *model-based learning*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: does money make people happier? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary: \n",
    "- You studied the data\n",
    "- You selected a model\n",
    "- You trained it on the training data (i.e., the learning algorithm searched for the model parameter values that minimize a cost function). \n",
    "- Finally, you applied the model to make predicitons o new cases (this is called *inference*), hoping that this model will generalize well. \n",
    "\n",
    "This is ehat a typical Machine Learning project looks like. \n",
    "We have covered a lot of ground so far: you now know what Machine Learning is really about, why it is useful, what some of the most common categories of ML systems are, and what a typical project workflow looks like. \n",
    "Now let's look at wha can go wrong in learning and prevent you form making accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Challenges of Machine Learning \n",
    "\n",
    "In short, since your main task is to select a learning algorithm and train it on some data, the two things that can go wrong are \"bad algorithm\" and \"bad data\". \n",
    "\n",
    "### Insufficient Quantity of Training Data \n",
    "It takes a lot of data for most Machine Learning algorithms to work properly. \n",
    "\n",
    "\n",
    "### Nonrepresentative Training Data \n",
    "In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to. \n",
    "This is true whether you use instance-based learning or model-based learning. \n",
    "\n",
    "If the sample is too small, you will have a *sampling noise* (i.e., nonrepresentative data as a result of chance), but even very large samples can be nonrepresentative if the sampling method is flawed. This is called *sampling bias*. \n",
    "\n",
    "### Poor-Quality Data \n",
    "Obviously, if your training data is full of errors, outliers, and noise (e.g., due to poor quality measurements), it will make it harder for the system to detect the underlying patterns, so your system is less likely to perform well. \n",
    "It is often well worth the effort to spend time cleaning up your training data. \n",
    "\n",
    "### Irrelevant Features \n",
    "Your system will only be capable of learning if the training data contains enoufh relevant features and not too many irrelevant ones. \n",
    "A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. \n",
    "This process, called *feature engineering*, involves the following steps: \n",
    "\n",
    "\n",
    "### Overfitting the Training Data \n",
    "\n",
    "*Overfitting*: it means that the model performs well on the training data, but it does not generalize well. \n",
    "\n",
    "Complex models such as deep neural networks can detect subtle patterns in the data, but if the training set is noisy, or if it is too small (which introduces sampling noise), then the model is likely to detect patterns in the noise itself. \n",
    "Obviously these patterns will not generalize to new instances. \n",
    "\n",
    "> Overfitting happens when the model is too complex relative to the amount and noisiness of the training data. Here are possible solutions: \n",
    "> * Simplify the model by selecting one with fewer parameters, by reducing the number of attributes in the training data, or by constraining the model. \n",
    "> * Gather more training data\n",
    "> * Reduce the noise in the training data (e.g. fix data errors and remove outliers). \n",
    "\n",
    "Constraining a model to make it simpler and reduce the risk of overfitting is called **regularization**. \n",
    "\n",
    "\n",
    "### Underfitting the Training Data \n",
    "It occurs when your model is too simple to learn the underlying structure of the data. \n",
    "Reality is just more complex than the model, so tis predictions are bound to be inaccurate, even on the training examples. \n",
    "\n",
    "Main options for fixing this problem: \n",
    "* Select a more powerful model, with more parameters. \n",
    "* Feed better features to the learning algorithm (feature engineering)\n",
    "* Reduce the constraints on the model (e.g., reduce the regularization hyperparameter).\n",
    "\n",
    "### Stepping Back \n",
    "\n",
    "The big picture: \n",
    "* Machine Learning is about making machines get better at some task by learning from data, instead of having to explicitly code rules. \n",
    "* There are many different types of ML systems: supervised or not, batch or online, instance-based or model-based. \n",
    "* In an ML project you gather data in a training set, and you feed the training set to a learning algorithm. If the algorithm is model-based, it tunes some parameters to fit the model to the training set (i.e., to make good predictions on the training set itself), and then hopefully it will be able to make good predictions on new cases as well. If the algorithm is instance-based, it just learns the examples by heart and generalizes to new instances by using a similarity measure to compare them to the learned instances. \n",
    "* The system will not perform well if your training set is too small, or if the data is not representative, is noisy, or is polluted with irrelevant features (garbage in, garbage out). Lastly, your model needs to be neither too simple (in which case it will underfit) nor too complex (in which case it will overfit).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Validating\n",
    "The only way to know how well a model will generalize to new cases is to actually try it out on new cases. \n",
    "One way to do tat is to put your model in production and monitor how well it performs. \n",
    "This works well, but if your model is horribly bad, your users will complain --not the best idea. \n",
    "\n",
    "A better option is to split your data into two sets: \n",
    "the **training set** and the **test set**. \n",
    "The error rate on new cases is called the *generalization error* (or *out-of-sample error*), and by evaluating your model on the test set, you get an estimate of this error. \n",
    "This value tells you haw well your model will perform on instances it has never seen before. \n",
    "\n",
    "If the training error is low but the generalization error is high, it means that your model is overfitting the training data. \n",
    "\n",
    "> It is common to use 80% of the data for training and *hold out* 20% for testing. However, this depends on the size of the dataset: if it contains 10 million instances, then holding out 1% means your test set will contain 100,000 instances, probably more than enough to get a good estimate of the generalization error. \n",
    "\n",
    "### Hyperparameter Tuning and Model Selection \n",
    "Evaluating a model is simple enough: just use a test set. \n",
    "Suppose you are hesitating between two types of models. One option is to train both and compare how well they generalize using the test set. \n",
    "\n",
    "**Holdout validation**\n",
    "You hold out part of the training set to evaluate several candidate models and select the best one. \n",
    "The new held-out set is called the **validation set** (or sometimes **development set**, or **dev set**). \n",
    "More specifically, you train multiple models with various hyperparameters you select the model that performs best on the validation set. \n",
    "After this holdout validation process, you train the best model on the full training set (including the validation set), and this gives you the final model. Lastly, you evaluate this final model on the test set to get an estimate of the generalization error. \n",
    "\n",
    "This solution usually works quite well. \n",
    "However, if the validation set is too small, then model evaluations will be imprecise: you may end up selecting a suboptimal model by mistake. \n",
    "Conversely, if the validation set is too large, then the remaining training set will be much smaller than the full training set. Since the final model will be trained on the full training set, it is not ideal to compare candidate models trained on a much smaller training set. \n",
    "One way to solve this problem is to perform repeated **cross-validation**, using many small validation sets. \n",
    "Each model is evaluated once per validation set after it is trained on the rest of the data. \n",
    "By averaging out all the evaluations of a model, you get a much more accurate measure of its performance. \n",
    "There is a drawback, however: the training time is multiplied by the number of validation sets. \n",
    "\n",
    "\n",
    "### Data Mismatch \n",
    "\n",
    "In some cases, it's easy to get a large amount of data for training, but his data probably won't be perfectly representative of the data that will be used in production. \n",
    "\n",
    "The validation set and the test set must be as representative as possible of the data you expect to use in production. \n",
    "\n",
    "\n",
    "### No Free Lunch Theorem \n",
    "A model is a simplified version of the observations. \n",
    "The simplifications are meant to discard the superfluous details that are unlikely to generalize to new instances. \n",
    "To decide what data to discard what data to keep, you must make **assumptions**. \n",
    "David Wolpert demonstrated that if you make absolutely no assumption about the data, then there is no reason to prefer one model over any other. \n",
    "This is called the **No Free Lunch (NFL) theorem**. \n",
    "There is no model that is *a priori* guaranteed to work better. \n",
    "The only way to know for sure which model is best is to evaluate them all. \n",
    "Since this is not possible, in practice you make some reasonable assumptions about the data and evaluate only a few reasonable models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd04bb85e28578f4d28f65069915c3f2718f8efd68328f075a674f53eac28597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
